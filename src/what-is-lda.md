# 1. LDAとは何か？

LDA (Latent Dirichlet Allocation) は離散データの集合に対する生成的確率モデルであり，Blei, Ng, and Jordan 2003によって考案された．一般的にLDAは，トピックモデリングとして知られる，テキストの集合をモデリングするために使われる．

トピックとは，単語上における確率分布である (Steyvers and Griffiths 2007)．[このことを理解する比喩として] あなたはバッグを持っていて，その中には単語が書かれた四角いカードがたくさん入っていると想像して欲しい（これはスクラブルというゲームに似ているが，カードの単位はアルファベット1字ではなく単語であるところが違う）．バッグに入っていない単語が存在する確率はゼロである．そして，すべてのバッグに入っている単語の確率はゼロより大きい確率で存在する．仮に今，バッグの中に'Philadelphia'という単語が2つ，'Eagles'という単語が1つ入っているとする．するとこのバッグから'Eagles'を引く確率は1/3，'Philadelphia'を引く確率は2/3，他の単語を引く確率は0と言えるだろう．これは意味のあるトピックである．それは与えられたトピックのための単語の集合の確率を与えている．

LDAの一般的なアイデアは，各々の文書 (document) はいくつものトピックの混合から生成されるものであり，各々のトピックは単語の混ぜ合わせから成っていることである．これは新しい文書を，アプリオリに与えたトピックから生成するモデルとして応用できる．またはすでに手元にある文書の集合に存在するトピックを推測することもできる．

LDAというモデル名に関して，あなたは [現時点で] 以下のような考えを持つことができるだろう：

* **Latent (潜在的)**： 文書中のトピックの構造は**潜在的**である．つまりテキスト中の**隠れた**構造であることを意味する．
* **Dirichlet (ディリクレ)**：ディリクレ分布は，文書内の各トピックの混合比率と各単語の混合比率を決定する．
* **Allocation (配分)**：与えられた各トピックへの単語の配分を行う．

以上をまとめると：我々はコーパス中に潜在的構造を持っており(トピック)，ディリクレ分布に基づいて，各々の文書の中にはトピックの分布，各々のトピックの中には単語の分布が存在し，与えられた文書に対してトピックの配分，トピックに対しては単語の配分が行われる．

一部の読者は以上で言及された専門用語や[確率]分布に慣れ親しんでいないことと思う．しかしそんな人にこそ本書を読み進めていただきたい．ナットとボルト[のような専門用語と数学]は以下に続く章のなかですべて説明し，しかしLDAが何であるか，なぜそれが役に立つのか理解するのを助けるために，簡単な例を示していく．以下の章では数学と技術的概念について説明を行う．

## 1.1 動物ジェネレーター

この本の大部分は単語，トピック，そして文書に関するものであるが，ここでは少し変わった視点から始めてみよう：動物とそれらの生息地域について考えてみる．動物を分類する一つの方法は，それらが陸地，空，海のどこで大部分の時間を過ごしたかに依ることである．明らかに，これらのうち一箇所にしか居住できない動物が存在する：牛は陸地にしか生息できないし，魚は海にしか生息できない．しかしながら，鳥のような動物は，陸地，海，空にわたって時間を按分して過ごしている．

ここであなたは次のように思っているかもしれない．「こんなことを考えて著者はどこに行こうとしているのだ？」．我々は陸地，海，そして空を，動物の分布を含むトピックとして考えることができる．この場合は動物を単語と同一視することができる．例として，陸地では鯨より牛を見る可能性が非常に高いが，海ではその逆になる[ということを考える]．これらの確率を生息地のタイプ (陸地，海，空 - つまりトピック) 毎に全ての動物 (単語) に渡って定量化したならば，それを使って陸地，海，空 (のトピック)が混在しているであろう，ある与えられた地域 (文書) に居住している動物の集合を生成することができる．

では特定の地域を生成するということをやってみよう．我々はどんな [タイプの] 生息地が存在するかによって，その地域が異なるということを知っている．例えば，ビーチは陸地，海，空を含むが，内陸にある砂漠のような場所は陸地と空しか含まないだろう．それぞれの地域を生息地のタイプの混合として定義することができる．例として，ビーチは 1/3 が陸地，1/3 が海，1/3 が空として定義できる．ビーチは単一の文書をなしていると考えることができる．まとめると：ある与えられた地域 (文書) は陸地，空，そして海 (というトピック) の混合であり，それぞれのトピックは動物 (単語) の相異なる混合を含んでいる．

自前の動物と生息地を用意して具体例を試してみよう．この章で提供される例は，LDAがどのように動作するかを概観するために非常に単純化されている．

我々のビーチ地域を 1/3 の陸生動物，1/3 の海棲動物，1/3 の飛行動物で生成するところから始める．以下にトピック毎の動物の存在確率のリストを示す．ある動物は与えられたトピックに対してゼロの存在確率しか持たないことが見て取れるだろう．例えば牛は海洋には絶対に存在しない．またある動物は他の動物より高い確率で存在することがわかる：カニは海に時おり見られる程度だが，魚は常に海に存在する．また空のカテゴリに一種類の動物しか居ないことに気づかれたかもしれない．現実には様々な鳥が存在するが，我々の語彙には飛べる鳥が1種類しかいないことになっている．

> これらは与えられたトピックに対する単語の存在確率であり，したがってそれぞれの生息地 (列) について総和は 1 になる．

<center> Table 1.1: 各生息地における動物の分布 </center>

| vocab  | land  | sea  | air |
|--------|-------|------|-----|
|🐋 	 | 0.00  | 0.12 | 0   |
|🐳 	 | 0.00  | 0.12 | 0   |
|🐟 	 | 0.00  | 0.12 | 0   |
|🐠 	 | 0.00  | 0.12 | 0   |
|🐙 	 | 0.00  | 0.12 | 0   |
|🦀 	 | 0.05  | 0.06 | 0   |
|🐊 	 | 0.05  | 0.06 | 0   |
|🐢 	 | 0.05  | 0.06 | 0   |
|🐍 	 | 0.05  | 0.06 | 0   |
|🐓 	 | 0.10  | 0.00 | 0   |
|🦃 	 | 0.10  | 0.00 | 0   |
|🐦 	 | 0.05  | 0.06 | 1   |
|🐧 	 | 0.05  | 0.06 | 0   |
|🐿 	 | 0.10  | 0.00 | 0   |
|🐘 	 | 0.10  | 0.00 | 0   |
|🐂 	 | 0.10  | 0.00 | 0   |
|🐑 	 | 0.10  | 0.00 | 0   |
|🐪 	 | 0.10  | 0.00 | 0   |

以上の記述に基づいてビーチ (文書) を生成するには，これらの確率表を用いて実直な実装を行う：

```r
words_per_topic <- 3
equal_doc <- c(vocab[sample.int(length(vocab),words_per_topic, prob=phi_ds$land, replace = T)],
               vocab[sample.int(length(vocab),words_per_topic, prob=phi_ds$sea, replace = T)],
               vocab[sample.int(length(vocab),words_per_topic, prob=phi_ds$air, replace = T)])
cat(equal_doc)
```

```
## 🐘 🐂 🐪 🐧 🐧 🐙 🐦 🐦 🐦
```

上の例では，トピックの混合は静的かつ等しく現れ，それぞれの生息地 (トピック) について 3 匹ずつ動物が寄与している．

先に進む前に，Tim Hopper が生成的 LDA の動作について emoji を利用して光を当てたプレゼンについて言及しておく (Hopper 2016)．

続いて海洋 (ocean) をセッティングしてみよう．海洋は海と空だけが存在するので，文書中のトピック分布は 50% が海，50% が空，そして 0% が陸地である．

```r
words_per_topic <- 3
ocean_doc <- c(vocab[sample.int(length(vocab),words_per_topic, prob=phi_ds$sea, replace = T)],
               vocab[sample.int(length(vocab),words_per_topic, prob=phi_ds$air, replace = T)])
cat(ocean_doc)
```

```
## 🐋 🐳 🐢 🐦 🐦 🐦
```

上の例では海と空のみが海洋地域に寄与するとしている．ゆえに双方のトピックが同数の動物を[海洋]地域に寄与している．

## 1.1.1 混合の生成

上の例が，あらかじめ決められたトピック混合と静的な単語を用いたものであったことに注意することは重要であるが，これらの混合はディリクレ分布からサンプリングするだけで作成できるのである．このことは，LDA を用いて文書のトピック構造をいかに推定するかという方法論の基礎となるため，重要な特徴である．LDA におけるディリクレ分布とその役割については後の章で詳細を議論する．

## 1.2 推定

これまでに，与えられた地域を代表する動物の集合を生成できることを見てきた．もし幾千もの地域があり，その陸地，空，海の混合割合を知りたいと思った時，どうすればよいだろうか？　あるいはもし，各々の動物がどれくらいの期間過ごすかについて全く分からない時，どうすればよいだろうか？　LDA はこれらの情報の両方を推論することを可能にする．ここでは前の例で地域 (文書) を生成したときのように，様々な生息地の混合と異なる長さからなる 100 のランダムな文書を生成する．

<center> Table 1.2: ある 2 つの地域における動物の出現 </center>

| Document | Animals |
|----------|---------|
| 1 	   | 🐪 🐘 🐪 🐘 🐦 🐓 🐪 🐪 🐍 🐪 🐧 🦀 🦀 🐪 🐓 🐍 🐘 🐓 🐍 🐿 🐧 🐢 🐧 🦃 🦃 🐧 🐦 🐑 🐑 🐊 🐳 🦀 🦀 🐿 🐢 🐢 🐿 🐓 🐪 🐊 🐘 🐦 🐪 🐂 🐍 🐓 🐍 🐓 🐦 🐍 🦃 🐦 🐪 🐍 🐿 🐦 🐦 🐂 🐿 🐍 🐂 🐿 🐦 🐦 🐑 🐂 🐓 🐓 🐧 🐑 🐦 🐪 🐦 🐧 🐿 🐪 🐦 🐢 🦃 🐿 🦃 🐦 🐑 🐊 🦃 🐪 🦃 🐓 🐂 🐊 🐊 🐂 🦃 |
| 2 	   | 🐙 🐂 🐦 🐦 🐓 🐧 🐪 🐙 🐧 🐙 🐪 🐘 🐋 🐂 🐦 🐧 🐦 🐙 🐦 🐳 🐟 🐊 🐟 🐢 🐠 🐠 🐪 🐢 🐦 🐘 🐍 🐳 🦃 🐟 🐙 🦀 🐊 🐳 🐪 🐠 🐧 🐢 🐢 🐦 🐍 🐧 🐿 🐢 🐪 🐢 🐧 🐓 🐑 🐳 🐧 🐍 🐊 🐂 🦃 🐋 🐪 🐓 🐿 🐟 🐙 🐋 🦀 🐂 🐦 🐳 🐢 🐟 🐦 🐘 🐊 🐓 🐓 🐧 🐊 🐢 🐪 🐓 🐊 🐢 🐑 🐢 🐙 🐊 🐢 🐧 🐪 |

以前 Table 1.1 で示されたトピック単語分布は，サンプル文書を生成するために使われていた．上の 2 つの文書を生成するために，Table 1.3 に示す真の生息地 (トピック) の混合比率を用いている．


<center> Table 1.3: 上記 2 つの生息地の分布</center>

| Document  | air  | land  | sea  |
|-----------|------|-------|------|
| 1         | 0.09 | 0.90  | 0.01 |
| 2         | 0.09 | 0.51  | 0.39 |

LDA の助けを借りると，すべての文書を見通してから，トピック/単語 (生息地/動物) 分布とトピック/文書 (生息地/地域) 分布を推定することができる．

真の分布と推定された単語/トピック分布を Table 1.4 に示す．

<center > Table 1.4: トピック毎の真の単語分布と推定された単語分布</center>

|     |  air estimated  | air 	| land estimated | land | sea estimated |  sea |
|-----|-----------------|-------|----------------|------|---------------|------|
| 🐋  | 	0.00        |  	0 	|  	     0.00    | 0.00 | 0.11 	        | 0.12 |
| 🐳  | 	0.01        |  	0 	|  	     0.01    | 0.00 | 0.10 	        | 0.12 |
| 🐟  | 	0.00        |  	0 	|  	     0.00    | 0.00 | 0.11 	        | 0.12 |
| 🐠  | 	0.00        |  	0 	|  	     0.00    | 0.00 | 0.12 	        | 0.12 |
| 🐙  | 	0.00        |  	0 	|  	     0.00    | 0.00 | 0.12 	        | 0.12 |
| 🦀  | 	0.01        |  	0 	|  	     0.04    | 0.05 | 0.06 	        | 0.06 |
| 🐊  | 	0.00        |  	0 	|  	     0.05    | 0.05 | 0.07 	        | 0.06 |
| 🐢  | 	0.01        |  	0 	|  	     0.05    | 0.05 | 0.06 	        | 0.06 |
| 🐍  | 	0.00        |  	0 	|  	     0.06    | 0.05 | 0.05 	        | 0.06 |
| 🐓  | 	0.00        |  	0 	|  	     0.10    | 0.10 | 0.00 	        | 0.00 |
| 🦃  | 	0.00        |  	0 	|  	     0.10    | 0.10 | 0.00 	        | 0.00 |
| 🐦  | 	0.95        |  	1 	|  	     0.02    | 0.05 | 0.11 	        | 0.06 |
| 🐧  | 	0.00        |  	0 	|  	     0.05    | 0.05 | 0.06 	        | 0.06 |
| 🐿  | 	0.00        |  	0 	|  	     0.10    | 0.10 | 0.01 	        | 0.00 |
| 🐘  | 	0.00        |  	0 	|  	     0.10    | 0.10 | 0.00 	        | 0.00 |
| 🐂  | 	0.00        |  	0 	|  	     0.10    | 0.10 | 0.00 	        | 0.00 |
| 🐑  | 	0.00        |  	0 	|  	     0.10    | 0.10 | 0.01 	        | 0.00 |
| 🐪  | 	0.00        |  	0 	|  	     0.11    | 0.10 | 0.00 	        | 0.00 |

最初の 5 つのドキュメントについて[真の]文書トピックの混合比率と推定された混合比率を示す．

<center> Table 1.5: 生成された最初の 5 つの文書の推定されたトピック分布 </center>

| Location | air estimated | air 	| land estimated | land 	| sea estimated | sea  |
|----------|---------------|--------|----------------|----------|---------------|------|
| 1 	   | 0.09 	       | 0.09 	| 0.90 	         | 0.90 	| 0.01 	        | 0.01 |
| 2 	   | 0.05 	       | 0.09 	| 0.46 	         | 0.51 	| 0.48 	        | 0.39 |
| 3 	   | 0.41 	       | 0.36 	| 0.54 	         | 0.64 	| 0.05 	        | 0.00 |
| 4 	   | 0.53 	       | 0.50 	| 0.45 	         | 0.48 	| 0.02 	        | 0.01 |
| 5 	   | 0.47 	       | 0.41 	| 0.25 	         | 0.40 	| 0.27 	        | 0.19 |
| 6 	   | 0.03 	       | 0.02 	| 0.35 	         | 0.38 	| 0.62 	        | 0.59

単語/トピック分布と文書/トピック分布の両方の推定結果について，文書を生成するのに用いた真の分布からばらつきがあることが見て取れると思う．それぞれの文書における，推定されたトピックと真のトピックのコサイン類似度を以下に示す．

<center> Table 1.6: 推定された文書/トピック分布と真の分布のコサイン類似度</center>

| air 	| land 	| sea  |
|-------|-------|------|
| 0.99 	| 0.99 	| 0.99 |

<center> Table 1.7: 推定されたトピック/単語分布と真の分布のコサイン類似度</center>

| air 	| land | sea  |
|-------|------|------|
| 1.00 	| 0.99 | 0.98 |
